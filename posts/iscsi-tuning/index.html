

<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="UTF-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge"><meta name="robots" content="index, follow"><link rel="author" href="/humans.txt">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.svg" type="image/svg+xml"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<meta name="msapplication-TileImage" content="/mstile-144x144.png">
<meta name="theme-color" content="#494f5c">
<meta name="msapplication-TileColor" content="#494f5c">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#494f5c"><meta name="author" content="Daniel Krieger"><meta name="description" content="Optimizing iSCSI Performance in an Unraid Environment">

  <meta itemprop="name" content="iSCSI Tuning">
  <meta itemprop="description" content="Optimizing iSCSI Performance in an Unraid Environment">
  <meta itemprop="datePublished" content="2024-12-08T12:21:20+01:00">
  <meta itemprop="dateModified" content="2024-12-08T12:21:20+01:00">
  <meta itemprop="wordCount" content="1084">
  <meta itemprop="image" content="https://sdn-warrior.org/images/head.jpg">
  <meta itemprop="keywords" content="Unraid,Vmware,Esxi,Iscsi,Homelab"><meta property="og:url" content="https://sdn-warrior.org/posts/iscsi-tuning/">
  <meta property="og:site_name" content="SDN-Warrior | Daniel Krieger">
  <meta property="og:title" content="iSCSI Tuning">
  <meta property="og:description" content="Optimizing iSCSI Performance in an Unraid Environment">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-08T12:21:20+01:00">
    <meta property="article:modified_time" content="2024-12-08T12:21:20+01:00">
    <meta property="article:tag" content="Unraid">
    <meta property="article:tag" content="Vmware">
    <meta property="article:tag" content="Esxi">
    <meta property="article:tag" content="Iscsi">
    <meta property="article:tag" content="Homelab">
    <meta property="og:image" content="https://sdn-warrior.org/images/head.jpg">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://sdn-warrior.org/images/head.jpg">
  <meta name="twitter:title" content="iSCSI Tuning">
  <meta name="twitter:description" content="Optimizing iSCSI Performance in an Unraid Environment">

<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "iSCSI Tuning",
    "name": "iSCSI Tuning",
    "description": "Optimizing iSCSI Performance in an Unraid Environment",
    "keywords": ["unraid", "vmware", "esxi", "iscsi", "homelab"],
    "articleBody": "In my setup, I use iSCSI in combination with Unraid to create a DIY block storage solution. Unraid, with its flexibility, serves as the foundation, and I utilize the Linux iSCSI implementation installed via a plugin to enable block-level storage.\nFor my setup, I use an Intel NUC of the 13th generation, equipped with two 2.5G network adapters. These provide the necessary connectivity for storage traffic. I configured two VMkernel (VMK) adapters specifically for iSCSI traffic, ensuring redundancy and optimized throughput.\nTo further enhance performance, I’ve implemented several optimizations, including fine-tuning settings on my ESXi servers.\nOptimize MaxIoSizeKB One such optimization involves adjusting the maximum I/O size for iSCSI traffic.\nInfo\rBy default, VMware ESXi uses a MaxIoSizeKB value of 128 KB.\rWhile this is sufficient for many setups, it may not be optimal for environments like mine, where jumbo frames are enabled across the network. Larger packets perform better in such a configuration, reducing overhead and increasing throughput.\nTo take advantage of my network’s capabilities, I increased the MaxIoSizeKB parameter to 512 KB\nTo configure this, I ran the following command on my ESXi host:\nesxcli system settings advanced set -o /ISCSI/MaxIoSizeKB -i 512 This change allows the iSCSI initiator to send larger I/O requests, improving data transfer efficiency in my jumbo-frame-enabled network. With this configuration, I noticed a significant improvement in performance, as the network could handle larger blocks of data more effectively.\nAttention\rFor this change to take effect, a host reboot is required. After restarting the ESXi server, the new value will be applied, enabling the iSCSI initiator to send larger I/O requests.\rAfter the reboot, you can verify that the change has been successfully applied by running the following command:\nesxcli system settings advanced list -o /ISCSI/MaxIoSizeKB The output should look like this:\n[root@esxnuc1:~] esxcli system settings advanced list -o /ISCSI/MaxIoSizeKB\rPath: /ISCSI/MaxIoSizeKB\rType: integer\rInt Value: 512\rDefault Int Value: 128\rMin Value: 128\rMax Value: 512\rString Value: Default String Value: Valid Characters: Description: Maximum Software iSCSI I/O size (in KB) (REQUIRES REBOOT!)\rHost Specific: false\rImpact: reboot Optimize multipathing To optimize performance, I configured Round Robin as the multipathing policy for my iSCSI volumes on the ESXi server. This ensures better load distribution and failover capabilities. The configuration can be applied via the ESXi CLI as follows:\nList all connected storage devices to identify the target naa or eui identifier: esxcli storage nmp device list Output naa.60014058f1117188efe49cb8b5de2273\rDevice Display Name: LIO-ORG iSCSI Disk (naa.60014058f1117188efe49cb8b5de2273)\rStorage Array Type: VMW_SATP_ALUA\rStorage Array Type Device Config: {implicit_support=on; explicit_support=on; explicit_allow=on; alua_followover=on; action_OnRetryErrors=on; {TPG_id=0,TPG_state=AO}}\rPath Selection Policy: VMW_PSP_MRU\rPath Selection Policy Device Config: {policy=iops,iops=1000,bytes=10485760,useANO=0; lastPathIndex=0: NumIOsPending=0,numBytesPending=0}\rPath Selection Policy Device Custom Config: policy=iops;iops=1000;bytes=10485760;samplingCycles=16;latencyEvalTime=180000;useANO=0;\rWorking Paths: vmhba64:C1:T0:L1, vmhba64:C0:T0:L1\rIs USB: false Info\rThe default multipath policy is “Most Recently Used” (VM_PSP_MRU).\rSet the multipathing policy for the desired iSCSI device to RoundRobin: esxcli storage nmp device set --device --psp VMW_PSP_RR Verify that the policy has been successfully applied: esxcli storage nmp device list | grep Info\rReplace with the actual identifier of your iSCSI device (naa.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx).\"\rOutput after chages naa.60014058f1117188efe49cb8b5de2273\rDevice Display Name: LIO-ORG iSCSI Disk (naa.60014058f1117188efe49cb8b5de2273)\rStorage Array Type: VMW_SATP_ALUA\rStorage Array Type Device Config: {implicit_support=on; explicit_support=on; explicit_allow=on; alua_followover=on; action_OnRetryErrors=on; {TPG_id=0,TPG_state=AO}}\rPath Selection Policy: VMW_PSP_RR\rPath Selection Policy Device Config: {policy=iops,iops=1000,bytes=10485760,useANO=0; lastPathIndex=0: NumIOsPending=0,numBytesPending=0}\rPath Selection Policy Device Custom Config: policy=iops;iops=1000;bytes=10485760;samplingCycles=16;latencyEvalTime=180000;useANO=0;\rWorking Paths: vmhba64:C1:T0:L1, vmhba64:C0:T0:L1\rIs USB: false Info\rthe multipath policy must now be VMW_PSP_RR\rTo further optimize path usage and load distribution, I adjusted the IOPS parameter for the Round Robin policy. By default, ESXi switches storage paths after 1000 I/O operations, but I used the following command snippet to change this behavior to switch after every single I/O:\nfor i in `esxcfg-scsidevs -c |awk '{print $1}' | grep naa.xxxx`; do esxcli storage nmp psp roundrobin deviceconfig set --type=iops --iops=1 --device=$i\rdone Where .xxxx matches the first few characters of your NAA IDs. Reducing the IOPS value from 1000 to 1 means the ESXi host will alternate between available paths much more frequently. In practice, this can help evenly distribute the workload across all paths, potentially improving overall responsiveness and performance.\nHowever, when combined with changes like increasing MaxIoSizeKB, the outcome can vary. In some cases, this adjustment may yield better results, while in others it could degrade performance. Therefore, it’s crucial to test these parameters individually for each storage environment to determine the most effective configuration.\nWhy Jumbo Frames Matter (bonus) Jumbo frames allow Ethernet frames larger than the standard 1500 bytes to be transmitted, reducing the total number of frames required to send the same amount of data. This results in lower CPU overhead and better performance, particularly in high-bandwidth and storage-intensive environments. However, it’s essential to ensure that every device in the network path—NICs, switches, and storage systems—supports and is configured for jumbo frames for optimal performance.\nTo verify that jumbo frames are functioning correctly in your environment, you can use the vmkping command on your ESXi host:\nvmkping -I vmk1 -s 8973 -d 192.168.67.250 vmkping parameters\rReplace vmk1 with the VMkernel adapter used for iSCSI. -s 8972 sets the packet size to match the jumbo frame size (8972 bytes, including headers). -d enables the Don’t Fragment flag to ensure the packet isn’t fragmented along the way. If you see the error: sendto() failed (Message too long) this indicates that the packet size is too large to be transmitted without fragmentation. For a setup with an MTU of 9000 configured on the distributed or standard switch, a packet size of 8972 bytes should work correctly. If the error occurs, check your vswitch settings, your physical switches and your iSCSI target.\nConclusion By increasing the MaxIoSizeKB to 512 KB, verifying jumbo frame functionality with vmkping, and enabling Round Robin, I optimized my iSCSI setup to leverage the full potential of my 2.5G network.\nCriytalDiskMark Benchmark\nIn my tests with CrystalDiskMark, I observed that both network adapters showed significant performance improvements as a result of these optimizations. These adjustments allow my Unraid and iSCSI configuration to deliver a robust and high-performance block storage solution tailored to my workloads.\nDisclaimer The settings and configurations described in this article are specific to my environment and were tested extensively within my setup. While these adjustments significantly improved performance for my use case, they may not be universally applicable. It’s essential to test these settings in your environment before implementing them, as results may vary depending on hardware, network, and workload specifics. These optimizations are not intended as a blanket recommendation.\n",
    "wordCount" : "1084",
    "inLanguage": "en",
    "image":"https://sdn-warrior.org/images/disc.jpg","datePublished": "2024-12-08T12:21:20+01:00",
    "dateModified": "2024-12-08T12:21:20+01:00",
    "author":{
        "@type": "Person",
        "name": "Daniel Krieger",
        "url": "https://sdn-warrior.org/about/"
        },
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://sdn-warrior.org/posts/iscsi-tuning/"
    },
    "publisher": {
      "@type": "Organization",
      "name": "SDN-Warrior | Daniel Krieger",
      "description": "",
      "logo": {
        "@type": "ImageObject",
        "url": "https://sdn-warrior.org/favicon.ico"
      }
    }
}
</script><title>iSCSI Tuning</title>
<link rel="stylesheet dns-prefetch preconnect preload prefetch" as="style" href="https://sdn-warrior.org/css/style.min.116f51d9e9113c7092c602012cc03c67b03685fa6df3e5ca96792fbbea366895.css" integrity="sha256-EW9R2ekRPHCSxgIBLMA8Z7A2hfpt8+XKlnkvu+o2aJU=" crossorigin="anonymous">
	<style>.bg-img {background-image: url('/images/disc.jpg');}</style></head>
<body id="page">
	<header id="site-header">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://sdn-warrior.org/">SDN-Warrior | Daniel Krieger</a>
				</div>
				<nav class="site-nav hide-in-mobile"><a href="https://sdn-warrior.org/posts/">Posts</a><a href="https://sdn-warrior.org/about/">About Me</a></nav>
			</div>
			<div class="hdr-right hdr-icons">
				<button id="img-btn" class="hdr-btn" title=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-image">
      <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
      <circle cx="8.5" cy="8.5" r="1.5"></circle>
      <polyline points="21 15 16 10 5 21"></polyline>
   </svg></button><span class="hdr-links hide-in-mobile"><a href="https://de.linkedin.com/in/daniel-krieger-6476591a9" target="_blank" rel="noopener me" title="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none"
   stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
   <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
   <rect x="2" y="9" width="4" height="12"></rect>
   <circle cx="4" cy="4" r="2"></circle>
</svg></a></span><button id="share-btn" class="hdr-btn" title=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-share-2">
      <circle cx="18" cy="5" r="3"></circle>
      <circle cx="6" cy="12" r="3"></circle>
      <circle cx="18" cy="19" r="3"></circle>
      <line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line>
      <line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line>
   </svg></button>
 
<div id="share-links" class="animated fast">
    
    
    
    
    <ul>
        <li>
            <a href="https://twitter.com/intent/tweet?hashtags=hermit2&amp;url=https%3a%2f%2fsdn-warrior.org%2fposts%2fiscsi-tuning%2f&amp;text=iSCSI%20Tuning" target="_blank" rel="noopener" aria-label="Share on X"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none"
   stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
   <path class="st0" d="m21.3 21.1 -11.4 -18.2h-7.2l11.4 18.2zm-18.6 0 7.2 -6.6m4.2 -5 7.2 -6.6" />
</svg></a>
        </li>
        <li>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsdn-warrior.org%2fposts%2fiscsi-tuning%2f" target="_blank" rel="noopener" aria-label="Share on Facebook"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none"
   stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
   <path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path>
</svg></a>
        </li>
        <li>
            <a href="mailto:?subject=iSCSI%20Tuning&amp;body=https%3a%2f%2fsdn-warrior.org%2fposts%2fiscsi-tuning%2f" target="_self" rel="noopener" aria-label="Share on Email"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none"
   stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
   <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
   <polyline points="22,6 12,13 2,6"></polyline>
</svg></a>
        </li>
        <li>
            <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsdn-warrior.org%2fposts%2fiscsi-tuning%2f&amp;source=https%3a%2f%2fsdn-warrior.org%2f&amp;title=iSCSI%20Tuning&amp;summary=iSCSI%20Tuning%2c%20by%20Daniel%20Krieger%0a%0aOptimizing%20iSCSI%20Performance%20in%20an%20Unraid%20Environment%0a" target="_blank" rel="noopener" aria-label="Share on LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none"
   stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
   <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
   <rect x="2" y="9" width="4" height="12"></rect>
   <circle cx="4" cy="4" r="2"></circle>
</svg></a>
        </li>
        <li>
            <a href="#" onclick="linkShare(&#34;iSCSI Tuning&#34;,&#34;https://sdn-warrior.org/posts/iscsi-tuning/&#34;,&#34;iSCSI Tuning, by Daniel Krieger\n\nOptimizing iSCSI Performance in an Unraid Environment\n&#34;); return false;" target="_self" rel="noopener" aria-label="Copy Link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy">
      <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
      <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
   </svg></a>
        </li>
    </ul>
</div><button id="menu-btn" class="hdr-btn" title=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
   </svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://sdn-warrior.org/posts/">Posts</a></li>
			<li><a href="https://sdn-warrior.org/about/">About Me</a></li>
		</ul>
	</div>


	<div class="bg-img"></div>
	<main class="site-main section-inner animated fadeIn faster"><article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Dec 8, 2024</span></div>
				<h1>iSCSI Tuning</h1>
			</header>
			<div class="post-info"><p>Optimizing iSCSI Performance in an Unraid Environment</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
   stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-feather">
   <path d="M20.24 12.24a6 6 0 0 0-8.49-8.49L5 10.5V19h8.5z"></path>
   <line x1="16" y1="8" x2="2" y2="22"></line>
   <line x1="17.5" y1="15" x2="9" y2="15"></line>
</svg><a href="/about/" target="_blank">Daniel Krieger</a></p>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon">
      <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path>
      <line x1="7" y1="7" x2="7" y2="7"></line>
   </svg><span class="tag"><a href="https://sdn-warrior.org/tags/unraid">unraid</a></span><span class="tag"><a href="https://sdn-warrior.org/tags/vmware">vmware</a></span><span class="tag"><a href="https://sdn-warrior.org/tags/esxi">esxi</a></span><span class="tag"><a href="https://sdn-warrior.org/tags/iscsi">iscsi</a></span><span class="tag"><a href="https://sdn-warrior.org/tags/homelab">homelab</a></span></p>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
      <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
      <polyline points="14 2 14 8 20 8"></polyline>
      <line x1="16" y1="13" x2="8" y2="13"></line>
      <line x1="16" y1="17" x2="8" y2="17"></line>
      <polyline points="10 9 9 9 8 9"></polyline>
   </svg>1084 Words
     Words // ReadTime
    
    
    
    4 Minutes, 55 Seconds</p>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
      <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
      <line x1="16" y1="2" x2="16" y2="6"></line>
      <line x1="8" y1="2" x2="8" y2="6"></line>
      <line x1="3" y1="10" x2="21" y2="10"></line>
   </svg>2024-12-08 12:21 &#43;0100</p></div>
			<hr class="post-end">
			<div class="content">
				<p>In my setup, I use iSCSI in combination with Unraid to create a DIY block storage solution. Unraid, with its flexibility, serves as the foundation, and I utilize the Linux iSCSI implementation installed via a plugin to enable block-level storage.</p>
<p>For my setup, I use an Intel NUC of the 13th generation, equipped with two 2.5G network adapters. These provide the necessary connectivity for storage traffic. I configured two VMkernel (VMK) adapters specifically for iSCSI traffic, ensuring redundancy and optimized throughput.</p>
<p>To further enhance performance, I’ve implemented several optimizations, including fine-tuning settings on my ESXi servers.</p>
<h2 id="optimize-maxiosizekb">Optimize MaxIoSizeKB<a href="#optimize-maxiosizekb" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>One such optimization involves adjusting the maximum I/O size for iSCSI traffic.</p>

    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info">
      <circle cx="12" cy="12" r="10"></circle>
      <line x1="12" y1="16" x2="12" y2="12"></line>
      <line x1="12" y1="8" x2="12.01" y2="8"></line>
   </svg></div><b>Info</b>
        </div>
        <div class="admonition-content">By default, VMware ESXi uses a <em><strong>MaxIoSizeKB</strong></em> value of 128 KB.</div>
    </aside>
<p>While this is sufficient for many setups, it may not be optimal for environments
like mine, where jumbo frames are enabled across the network. Larger packets perform better in such a configuration, reducing overhead and increasing throughput.</p>
<p>To take advantage of my network&rsquo;s capabilities, I increased the <em><strong>MaxIoSizeKB</strong></em> parameter to 512 KB</p>
<p>To configure this, I ran the following command on my ESXi host:</p>
<pre tabindex="0"><code>esxcli system settings advanced set -o /ISCSI/MaxIoSizeKB -i 512
</code></pre><p>This change allows the iSCSI initiator to send larger I/O requests, improving data transfer efficiency in my jumbo-frame-enabled network. With this configuration, I noticed a significant improvement in performance, as the network could handle larger blocks of data more effectively.</p>

    <aside class="admonition attention">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" class="feather feather-link" width="24" height="24" viewBox="0 0 24 24"
      fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
      <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
   </svg></div><b>Attention</b>
        </div>
        <div class="admonition-content">For this change to take effect, a host reboot is required. After restarting the ESXi server, the new value will be applied, enabling the iSCSI initiator to send larger I/O requests.</div>
    </aside>
<p>After the reboot, you can verify that the change has been successfully applied by running the following command:</p>
<pre tabindex="0"><code>esxcli system settings advanced list -o /ISCSI/MaxIoSizeKB
</code></pre><p>The output should look like this:</p>
<pre tabindex="0"><code>[root@esxnuc1:~] esxcli system settings advanced list -o /ISCSI/MaxIoSizeKB
   Path: /ISCSI/MaxIoSizeKB
   Type: integer
   Int Value: 512
   Default Int Value: 128
   Min Value: 128
   Max Value: 512
   String Value: 
   Default String Value: 
   Valid Characters: 
   Description: Maximum Software iSCSI I/O size (in KB) (REQUIRES REBOOT!)
   Host Specific: false
   Impact: reboot
</code></pre><h2 id="optimize-multipathing">Optimize multipathing<a href="#optimize-multipathing" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>To optimize performance, I configured Round Robin as the multipathing policy for my iSCSI volumes on the ESXi server. This ensures better load distribution and failover capabilities. The configuration can be applied via the ESXi CLI as follows:</p>
<ul>
<li>List all connected storage devices to identify the target naa or eui identifier:</li>
</ul>
<pre tabindex="0"><code>esxcli storage nmp device list
</code></pre><ul>
<li>Output</li>
</ul>
<pre tabindex="0"><code>naa.60014058f1117188efe49cb8b5de2273
   Device Display Name: LIO-ORG iSCSI Disk (naa.60014058f1117188efe49cb8b5de2273)
   Storage Array Type: VMW_SATP_ALUA
   Storage Array Type Device Config: {implicit_support=on; explicit_support=on; explicit_allow=on; alua_followover=on; action_OnRetryErrors=on; {TPG_id=0,TPG_state=AO}}
   Path Selection Policy: VMW_PSP_MRU
   Path Selection Policy Device Config: {policy=iops,iops=1000,bytes=10485760,useANO=0; lastPathIndex=0: NumIOsPending=0,numBytesPending=0}
   Path Selection Policy Device Custom Config: policy=iops;iops=1000;bytes=10485760;samplingCycles=16;latencyEvalTime=180000;useANO=0;
   Working Paths: vmhba64:C1:T0:L1, vmhba64:C0:T0:L1
   Is USB: false
</code></pre>
    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info">
      <circle cx="12" cy="12" r="10"></circle>
      <line x1="12" y1="16" x2="12" y2="12"></line>
      <line x1="12" y1="8" x2="12.01" y2="8"></line>
   </svg></div><b>Info</b>
        </div>
        <div class="admonition-content"><!-- raw HTML omitted --> The default multipath policy is &ldquo;Most Recently Used&rdquo; (VM_PSP_MRU).</div>
    </aside>
<ul>
<li>Set the multipathing policy for the desired iSCSI device to RoundRobin:</li>
</ul>
<pre tabindex="0"><code>esxcli storage nmp device set --device &lt;DeviceIdentifier&gt; --psp VMW_PSP_RR
</code></pre><ul>
<li>Verify that the policy has been successfully applied:</li>
</ul>
<pre tabindex="0"><code>esxcli storage nmp device list | grep &lt;DeviceIdentifier&gt;
</code></pre>
    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info">
      <circle cx="12" cy="12" r="10"></circle>
      <line x1="12" y1="16" x2="12" y2="12"></line>
      <line x1="12" y1="8" x2="12.01" y2="8"></line>
   </svg></div><b>Info</b>
        </div>
        <div class="admonition-content">Replace <!-- raw HTML omitted --> with the actual identifier of your iSCSI device (naa.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx).&quot;</div>
    </aside>
<ul>
<li>Output after chages</li>
</ul>
<pre tabindex="0"><code>naa.60014058f1117188efe49cb8b5de2273
   Device Display Name: LIO-ORG iSCSI Disk (naa.60014058f1117188efe49cb8b5de2273)
   Storage Array Type: VMW_SATP_ALUA
   Storage Array Type Device Config: {implicit_support=on; explicit_support=on; explicit_allow=on; alua_followover=on; action_OnRetryErrors=on; {TPG_id=0,TPG_state=AO}}
   Path Selection Policy: VMW_PSP_RR
   Path Selection Policy Device Config: {policy=iops,iops=1000,bytes=10485760,useANO=0; lastPathIndex=0: NumIOsPending=0,numBytesPending=0}
   Path Selection Policy Device Custom Config: policy=iops;iops=1000;bytes=10485760;samplingCycles=16;latencyEvalTime=180000;useANO=0;
   Working Paths: vmhba64:C1:T0:L1, vmhba64:C0:T0:L1
   Is USB: false
</code></pre>
    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info">
      <circle cx="12" cy="12" r="10"></circle>
      <line x1="12" y1="16" x2="12" y2="12"></line>
      <line x1="12" y1="8" x2="12.01" y2="8"></line>
   </svg></div><b>Info</b>
        </div>
        <div class="admonition-content">the multipath policy must now be VMW_PSP_RR</div>
    </aside>
<p>To further optimize path usage and load distribution, I adjusted the IOPS parameter for the Round Robin policy. By default, ESXi switches storage paths after 1000 I/O operations, but I used the following command snippet to change this behavior to switch after every single I/O:</p>
<pre tabindex="0"><code>for i in `esxcfg-scsidevs -c |awk &#39;{print $1}&#39; | grep naa.xxxx`; do 
   esxcli storage nmp psp roundrobin deviceconfig set --type=iops --iops=1 --device=$i
done
</code></pre><p>Where .xxxx matches the first few characters of your NAA IDs. Reducing the IOPS value from 1000 to 1 means the ESXi host will alternate between available paths much more frequently. In practice, this can help evenly distribute the workload across all paths, potentially improving overall responsiveness and performance.</p>
<p>However, when combined with changes like increasing MaxIoSizeKB, the outcome can vary. In some cases, this adjustment may yield better results, while in others it could degrade performance. Therefore, it’s crucial to test these parameters individually for each storage environment to determine the most effective configuration.</p>
<h2 id="why-jumbo-frames-matter-bonus">Why Jumbo Frames Matter (bonus)<a href="#why-jumbo-frames-matter-bonus" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>Jumbo frames allow Ethernet frames larger than the standard 1500 bytes to be transmitted, reducing the total number of frames required to send the same amount of data. This results in lower CPU overhead and better performance, particularly in high-bandwidth and storage-intensive environments. However, it’s essential to ensure that every device in the network path—NICs, switches, and storage systems—supports and is configured for jumbo frames for optimal performance.</p>
<p>To verify that jumbo frames are functioning correctly in your environment, you can use the <em><strong>vmkping</strong></em> command on your ESXi host:</p>
<pre tabindex="0"><code>vmkping -I vmk1 -s 8973 -d 192.168.67.250
</code></pre>
    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info">
      <circle cx="12" cy="12" r="10"></circle>
      <line x1="12" y1="16" x2="12" y2="12"></line>
      <line x1="12" y1="8" x2="12.01" y2="8"></line>
   </svg></div><b> vmkping parameters</b>
        </div>
        <div class="admonition-content"><ul>
<li>Replace <em><strong>vmk1</strong></em> with the VMkernel adapter used for iSCSI.</li>
<li><em><strong>-s 8972</strong></em> sets the packet size to match the jumbo frame size (8972 bytes, including headers).</li>
<li><em><strong>-d</strong></em> enables the Don&rsquo;t Fragment flag to ensure the packet isn&rsquo;t fragmented along the way.</li>
</ul>
</div>
    </aside>
<p>If you see the error:  <em><strong>sendto() failed (Message too long)</strong></em> this indicates that the packet size is too large to be transmitted without fragmentation. For a setup with an MTU of 9000 configured on the distributed or standard switch, a packet size of 8972 bytes should work correctly. If the error occurs, check your vswitch settings, your physical switches and your iSCSI target.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>By increasing the MaxIoSizeKB to 512 KB, verifying jumbo frame functionality with vmkping, and enabling Round Robin, I optimized my iSCSI setup to leverage the full potential of my 2.5G network.</p>

<figure><picture>
          <source srcset="/iscsi-tuning/test_hu12020423995241410634.webp" type="image/webp">
          <source srcset="/iscsi-tuning/test_hu16349894886800222160.jpg" type="image/jpeg">
          <img src="/iscsi-tuning/test_hu12020423995241410634.webp"alt="CriytalDiskMark Benchmark"  width="479"  height="351" />
        </picture><figcaption>
            <p>CriytalDiskMark Benchmark</p>
          </figcaption></figure>
<p>In my tests with CrystalDiskMark, I observed that both network adapters showed significant performance improvements as a result of these optimizations. These adjustments allow my Unraid and iSCSI configuration to deliver a robust and high-performance block storage solution tailored to my workloads.</p>
<h2 id="disclaimer">Disclaimer<a href="#disclaimer" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>The settings and configurations described in this article are specific to my environment and were tested extensively within my setup. While these adjustments significantly improved performance for my use case, they may not be universally applicable. It’s essential to test these settings in your environment before implementing them, as results may vary depending on hardware, network, and workload specifics. These optimizations are not intended as a blanket recommendation.</p>

			</div>
			

<div class="related-posts thin">
	<h2>See Also</h2>
	<ul>
	
	<li><a href="/posts/labv4/">Homelab V4</a></li>
	
	<li><a href="/posts/mac-learning/">MAC Learning is your friend</a></li>
	
	<li><a href="/posts/unraid-storage/">Unraid - A Storage Journey</a></li>
	
	<li><a href="/posts/nuc/">How to get most out of your Nuc </a></li>
	
	<li><a href="/posts/nsx-cert-exchange/">NSX 4.X Certificate exchange of the NSX Manager</a></li>
	
	</ul>
</div>

		</article>
		<div class="post-nav thin">
			<a class="next-post" href="https://sdn-warrior.org/posts/nsx4_2_1_1/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left">
      <line x1="19" y1="12" x2="5" y2="12"></line>
      <polyline points="12 19 5 12 12 5"></polyline>
   </svg>&nbsp;Newer</span><br><span>NSX 4.2.1.1 Hotfix Update</span>
			</a>
			<a class="prev-post" href="https://sdn-warrior.org/posts/mac-learning/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right">
      <line x1="5" y1="12" x2="19" y2="12"></line>
      <polyline points="12 5 19 12 12 19"></polyline>
   </svg></span><br><span>MAC Learning is your friend</span>
			</a>
		</div>
		<div id="comments" class="thin"></div>
	</main>

<footer id="site-footer" class="section-inner thin animated fadeIn faster">
	<p>
		&copy; 2024 <a href="https://sdn-warrior.org/">Daniel Krieger</a>
		&#183; COPYRIGHT Daniel Krieger</p>

</footer>
<script async src="https://sdn-warrior.org/js/bundle.min.c7c384e4d29d192bbac6811ae4660bb01767194a5bea56baca77e8260f93ea16.js" integrity="sha256-x8OE5NKdGSu6xoEa5GYLsBdnGUpb6la6ynfoJg+T6hY=" crossorigin="anonymous"></script><script async src="https://sdn-warrior.org/js/link-share.min.24409a4f6e5537d70ffc55ec8f9192208d718678cb8638585342423020b37f39.js" integrity="sha256-JECaT25VN9cP/FXsj5GSII1xhnjLhjhYU0JCMCCzfzk=" crossorigin="anonymous"></script>
</body>

</html>
